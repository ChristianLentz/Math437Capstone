{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Techniques for the Wave Equation\n",
    "## Math 437 Capstone Project, Fall 2023\n",
    "### Author: Christian Lentz\n",
    "\n",
    "The goal of this project will be to investigate numerical techniques for approximating solutions to PDEs. We will use finite differences to build a simple model for the wave equation with randomized initial conditions and periodic boundary conditions. We include a total of four implementations of finite differences. This will motivate discussions and comparisons of other numerical techniques and thier implementations, particularly the Fourier spectral method. We include one (partially complete) implementation of the Fourier spectral method using the Fast Fourier Transform through SciPy's FFT package.\n",
    "\n",
    "We start by briefly discussing the wave equation, and move directly into a discussion of finite differences and an implementation for the wave equation. Here, we motivate the technique by recalling classic results of Analysis, including the definition of the derivative and Cauchy's generalized mean value theorem. In addition, we also discuss the importance of the CFL condition when ensuring convergence of a finite differences program. Our statement of CFL is as defined by Courant, Friedrichs and Lewy, and our discussion of CFL is motivated by texts from Lui. \n",
    "\n",
    "Following finite differences, we discuss the Fourier Spectral method, and outline both the underlying mathematics and implementation. We start with a general discussion of other common numerical techniques, including spectral methods, as defined in texts from SÃ¼li. Next, a discussion of the continuous Fourier transform as it relates to the wave equation, in which we appeal to ODE techniques. After a discussion of the discrete Fourier transfrom and the FFT, which follows the logic of texts from Sauer, we end with a brief overview of an implementation of a Fourier spectral method for the wave equation. \n",
    "\n",
    "### 1  The Wave Equation\n",
    "\n",
    "The wave equation is a second order partial differential equation which describes both traveling and standing waves as they occur in classical physics. The equation is particularly useful in modeling mechanical waves, such as sound waves, or electromagnetic waves, such as light waves. Note that the wave equation is not the same as the wave function.\n",
    "\n",
    "Let $x$ be some $n$-dimensional vector $x = (x_1, x_2, \\dots x_n)$, and suppose that $u(x,t)$ describes the displacement of a system from an initial rest position. The wave equation will describe the acceleration of this displacement over time. Specifically, the scalar form of the wave equation is\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial^2 u}{\\partial t^2} &= c^2 (\\frac{\\partial^2 u}{\\partial x_{1}^2} + \\dots + \\frac{\\partial^2 u}{\\partial x_{n}^2})\n",
    "\\end{align*}, \n",
    "\n",
    "where $c \\in \\mathbb{R^{>0}}$ is some scalar. The vectorized form can be written as \n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial^2 u}{\\partial t^2} &= c^2 {\\nabla}^2 u \n",
    "\\end{align*}\n",
    "\n",
    "This form of the wave equation which we use assumes no friction. For this project, we will use finite difference and spectral methods to approximate solutions to the wave equation with periodic boundary conditons in order to investigate and compre the underlying numerical techniques.\n",
    "\n",
    "### 2  Finite Differences\n",
    "\n",
    "The finite differences method makes use of the definition of the derivative, or the difference quotient. However, rather than taking the limit, we will approximate solutions to the PDE at finitely many fixed points in time, hence why we call this finite differences. \n",
    "\n",
    "![Multiple solutions to the 1D wave equation with Finite Differences](visuals/1D_progress/FD_1D_5.png)\n",
    "\n",
    "#### 2.1  A bit of Analysis\n",
    "\n",
    "First, we recall the definition of the derivative. Suppose some function $f: E \\rightarrow \\mathbb{R}$ where $a \\in E$ is a limit point of $E \\subseteq \\mathbb{R}$. We say that $f$ is differentiable at $a$ if the following limit exists: \n",
    "\n",
    "\\begin{align*}\n",
    "    lim_{h \\rightarrow 0} &= \\frac{f(a + h)-f(a)}{h} \n",
    "\\end{align*}\n",
    "\n",
    "Equivalently, we may also write the difference quotient as: \n",
    "\n",
    "\\begin{align*}\n",
    "    lim_{h \\rightarrow 0} &= \\frac{f(a)-f(a - h)}{h} \n",
    "\\end{align*}\n",
    "\n",
    "Writing the difference quotient in either of these forms will be useful in proving the difference quotient for the second derivative of a function. To make our definition above more concise, it is also useful to recall that if $a \\in E$ is a limit point, then: \n",
    "\n",
    "\\begin{align*}\n",
    "    \\forall \\epsilon > 0: \\exists x \\in E: 0 < |x - a| < \\epsilon \n",
    "\\end{align*}\n",
    "\n",
    "In words, $E$ contains points which are arbitrarily close but not equal to $a$. This definition is the foundation of the finite differences approach. By manipulating the difference quotient, we can build a technique to approximte solutions to any ODE or PDE of any order. It is possible to do this since we can generalize the definition of the difference quotient to higher order derivatives as well. For our purpose, we will need to know the difference quotient for the second derivative of a function. \n",
    "\n",
    "$\\textit{Claim:}$ Let $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ be differentiable and let $a \\in \\mathbb{R}$. Further, suppose that $f''(a)$ exists. Then:\n",
    "\n",
    "\\begin{align*}\n",
    "    f''(a) &= lim_{h \\rightarrow 0} \\frac{f(a + h) + f(a - h) - 2f(a)}{h^2}\n",
    "\\end{align*}\n",
    "\n",
    "We can provide two proofs of this fact. The first is quite clear but is also quite an abuse of notation. The second makes use of Cauchy's generalized Mean Value Theorem. \n",
    "\n",
    "$\\textit{Proof 1:}$ Since $f''(a)$ exists, it follows that: \n",
    "\n",
    "\\begin{align*}\n",
    "    f''(a) &= lim_{h \\rightarrow 0} \\frac{f'(a + h) - f'(a)}{h} \n",
    "\\end{align*}\n",
    "\n",
    "Further, since $f$ is a differentiable function, then we have:\n",
    "\n",
    "\\begin{align*}\n",
    "    f''(a) &= lim_{h \\rightarrow 0} \\frac{\\frac{f(a + h_1) - f(a)}{h_1} - \\frac{f(a) - f(a - h_2)}{h_2}}{h} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Letting $h = h_1 = h_2$, then we may simplify to get the form stated in the claim, and this concludes the proof. Although this is concise, we cannot interchange the limits, nor is it appropriate to assume that $h = h_1 = h_2$. \n",
    "\n",
    "To provide our second proof, we first state the Cauchy MVT, without proof. \n",
    "\n",
    "$\\textit{Cauchy MVT:}$ Let $a < b$ and $f,g: [a,b] \\rightarrow \\mathbb{R}$. Assume that $f,g$ are continuous on $[a,b]$ and differentiable on $(a,b)$. Then, there exists $\\xi \\in (a,b)$ such that \n",
    "\n",
    "\\begin{align*}\n",
    "    f'(\\xi)(g(b)-b(a)) = g'(\\xi)(f(b)-f(a)).\n",
    "\\end{align*}\n",
    "\n",
    "Furthermore, under the assumtion that $g'(x) \\neq 0$ for all $x \\in (a,b)$, then we can write this result as\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{f'(\\xi)}{g'(\\xi)} &= \\frac{f(b)-f(a)}{g(b)-g(a)}.\n",
    "\\end{align*}\n",
    "\n",
    "Using this, we can provide a stronger proof of the claim above. \n",
    "\n",
    "$\\textit{Proof 2:}$ Consider the compact interval $[0,h]$ and define $F(x) = f(a+x) + f(a-x) - 2f(x)$  and $G(x) = x^2$ for $h > 0$. Consider $lim_{h \\rightarrow 0^{+}}$. We may apply Cauchy, as $F(x), G(x)$ are continuous on $[0,h]$ and differentiable on $(0,h)$ with $G(0) \\neq G(h)$. It follows that \n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{F(h) - F(0)}{G(h) - G(0)} &= \\frac{f(a+h) - f(a-h)-2f(a)}{h^2} \\\\\n",
    "    &= \\frac{f'(a + \\xi_h) + f'(a- \\xi_h)}{2 \\xi_h} \\\\ \n",
    "    &= \\frac{F'(\\xi_h)}{G'(\\xi_h)}\n",
    "\\end{align*}\n",
    "\n",
    "where $\\xi_h \\in (0, h)$ with $lim_{h \\rightarrow 0^{+}} \\xi_h = 0$. Evaluating this limit, we see that\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{f'(a + \\xi_h) + f'(a- \\xi_h)}{2 \\xi_h} &= \\frac{(f'(a + \\xi_h) - f(a)) + (f(a) - f'(a- \\xi_h))}{2 \\xi_h} \\\\ \n",
    "    &= \\frac{f''_{+}(a) + f''_{+}(a)}{2} \\\\ \n",
    "    &= f''_{+}(a)\n",
    "\\end{align*}\n",
    "\n",
    "Note that we must consider $lim_{h \\rightarrow 0^{-}}$ separately. Here we only consider the right derivative, and note that the case for the left derivative follows similarly. This concludes the proof. With this, we now have a stong understanding of the definition of the first and second derivative. Now we can use these facts to construct a method for approximating solutions to PDEs. \n",
    "\n",
    "#### 2.2  Finite Differences for the Wave Equation\n",
    "\n",
    "Here, we outline our finite diffeences technique for the wave equation. Consider the wave equation in two spatial dimensions $x$ and $y$: \n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial^2 u}{\\partial t^2} &= c^2 (\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2})\n",
    "\\end{align*}\n",
    "\n",
    "The first step of this process will be to write the PDE using the difference quotient. To make things a bit more intuitive, we will write the limits as $lim_{\\Delta t \\rightarrow 0}$, $lim_{\\Delta x \\rightarrow 0}$ and $lim_{\\Delta y \\rightarrow 0}$. Suppose that we let $x = a$, $y = b$ and $t = T$. Then we have:  \n",
    "\n",
    "\\begin{align*}\n",
    "    lim_{\\Delta t \\rightarrow 0} \\frac{u(a, b, T + \\Delta t) + u(a, b, T - \\Delta t) - 2u(a, b, T)}{(\\Delta t)^2} = \\dots\\\\\n",
    "    \\dots = c^2(lim_{\\Delta x \\rightarrow 0} \\frac{u(a + \\Delta x, b, T) + u(a - \\Delta x, b, T) - 2u(a, b, T)}{(\\Delta x)^2} + \\dots \\\\\n",
    "    \\dots + lim_{\\Delta y \\rightarrow 0} \\frac{u(a, b + \\Delta y, T) + u(a, b - \\Delta y, T) - 2u(a, b, T)}{(\\Delta y)^2}) \n",
    "\\end{align*}\n",
    "\n",
    "By inspection, we see that this is quite easy to generalize to the $n$-dimensional case. Although this form is quite cumbersome, we can leverage it to numerically approximate solutions to the wave equation. The key is to ignore the limit, and let $u(a,b,T+\\Delta t)$ be unknown. By doing this, we will be able to approximate solutions for fixed $t$ beyond our initial time $T$. Thus, we get something that looks like this:\n",
    "\n",
    "\\begin{align*}\n",
    "    u(a, b, T + \\Delta t) \\approx \\dots \\\\\n",
    "    \\dots \\approx 2u(a,b,T) - u(a, b, T - \\Delta t) + \\dots \\\\ \n",
    "    \\dots + \\frac{c^2 (\\Delta t)^2}{(\\Delta x)^2} (u(a + \\Delta x, b, T) + u(a - \\Delta x, b, T) - 2u(a, b, T)) + \\dots \\\\ \n",
    "    \\dots + \\frac{c^2 (\\Delta t)^2}{(\\Delta y)^2} (u(a, b + \\Delta y, T) + u(a, b - \\Delta y, T) - 2u(a, b, T)) \n",
    "\\end{align*}\n",
    "\n",
    "Using this equation, we can approximate solutions for our PDE. \n",
    "\n",
    "#### 3  Choosing $\\Delta x$, $\\Delta y$, and $\\Delta t$\n",
    "\n",
    "We must take care when chooisng parameter values for $\\Delta x$, $\\Delta y$, and $\\Delta t$ to assure the stability of our program. In certain cases, a poor choice for these parameters will result in our program producing incorrect solutions.\n",
    "\n",
    "Suppose our wave PDE with solutions of the form $u(x, y, t)$ where $x,y \\in R$ and $t \\in \\mathbb{R}^{>0}$. Such a PDE can be thought of as an infinite dimensional function space, where at each $t \\in \\mathbb{R}^{>0}$ we have a unique function describing a solution to the PDE. Numerical techniques for approximating solutions to such a PDE, including finite differences, will rely on a $\\textbf{discretization}$ of the function space to an finite sequence of probelms.\n",
    "\n",
    "Suppose that we wish to model our PDE over the time interval T = $[t_0, t_{max}]$. A discretization of the time variable will split this iterval into finitely many points by choosing some $\\Delta t$. The cardinality of this disretized set is: \n",
    "\n",
    "\\begin{align*}\n",
    "    N = \\frac{t_{max} - t_0}{\\Delta t} \n",
    "\\end{align*}\n",
    "\n",
    "And the set itself is \n",
    "\n",
    "\\begin{align*}\n",
    "    dT = \\{ t_0 + \\Delta t * i \\} \\text{ for } i \\in \\{1, \\dots, N\\}\n",
    "\\end{align*}\n",
    "\n",
    "By doing this, we have transformed the uncountably infinite interval $T$ into a finite sequence of $N$ probelms, where we approximate a solution to the PDE for each $t \\in dT$. We can easily generalize this to the case where we wish to model the PDE for all $t \\in \\mathbb{R}^{>0}$ by simply letting $t_0 = 0$ and $t_{max} = \\infty$. In this case, $dT$ is a countably infinite set. However, we must also place a discretization on the spatial variables as well. Thus, we must also choose some $\\Delta x$ and $\\Delta y$ in order to transform the space into a discretized grid. \n",
    "\n",
    "At a high level, we must choose these parameters such that $\\Delta t$ is not too large as too allow the wave to travel to another coordinate in the grid within that interval of time. We can ensure proper selection of these parameters by adhering to the $\\textbf{CFL condition}$, which is commonly used with finite differences to model advection like processes. The condition states that for a PDE with spatial variables $x = (x_1, \\dots, x_n)$ and temporal variable $t$, a discretization of these parameters must satisfy that \n",
    "\n",
    "\\begin{align*}\n",
    "    \\Delta t (\\sum_{i=1}^{n} \\frac{u_{x_i}}{\\Delta x_i}) \\leq C\n",
    "\\end{align*}\n",
    "\n",
    "where $C$ is a dimensionless constant and $u_{x_i}$ is the velocity with respect to $x_i$. We typically let $C = 1$. Essentially, the CFL conditions tells us that if we choose a small value for $\\Delta x$ and $\\Delta y$, we must also choose a sufficiently small value for $\\Delta t$ as well, thus ensuring convergence of our solutions. \n",
    "\n",
    "#### 4  Finite Differences Implementation\n",
    "\n",
    "In this project, we provide a total of four implementations of finite difference for the wave equation, including two implementations for both one and two spatial dimensions. For the one dimensional case, we include a slow implementation which loops over all spatial coordinates at each time step, and a vectorized implementation which makes use of NumPy arrays, thus allowing us to loop over only the temporal variable. \n",
    "\n",
    "For the two dimensional case, we include a vectorized implementation as well as an implementation which splits the probelms into two one dimensional probelms and \"stitches\" one dimensional solutions together at each time step. This implementation uses a vectorized approach to solve each one dimensional problem. \n",
    "\n",
    "We do not include pseudocode or a full discussion of these implementations here. Instead, we direct the reader interested in the finer details of these implementations to the file **FiniteDiff.py** in the github repository for this project. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5  Other Numerical Methods\n",
    "\n",
    "It is worth noting other common classes of numerical techniques, including Finite Element Methods (FEMs) and Finite Volume Methods. FEMs and Finite Elements both provide continuous or discontinuous piecewise approximations over a tesselation of the domain. While they are more similar to Finite Differences than Spectral Methods, they are considerably more difficult mathematically when compared to finite differences, and are also more difficult to implement. However, $\\textbf{Spectral Methods}$ can deliver highly accurate, $\\textbf{smooth}$ approximations for a solution to a PDE.  \n",
    "\n",
    "Spectral methods approximate solutions to PDEs in the form of fixed degree polynomials, which are $\\textbf{smooth}$ by definiton. Recall that for some open set $U$, any function $f: U \\rightarrow \\mathbb{R}$ is said to belong to the $\\textbf{differentiability class } C^n$ iff each higher-order derivative of $f$ in the set $\\{f^{(i)}\\}_{i=1}^{n}$ exists and is continuous over $U$. A smooth function belongs to the class $C^{\\infty}$, or is $\\textbf{infinitely differentiable}$. If the underlying function that we are applying the PDE to is a smooth function, then a spectral method can provide a highly accurate, smooth approximation. \n",
    "\n",
    "More specifically, Spectral Methods will seek an approximation in the form of a linear combination of a set of mutually $\\textbf{orthogonal polynomials}$. Suppose the following linear combination of polynomials over the reals:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\sum_{i=1}^{n} f_i(x)\n",
    "\\end{align*}\n",
    "\n",
    "For any two polynomials $f_j(x)$ and $f_k(x)$ for $j,k \\in \\{1, \\dots, n\\}$, we may define the inner product\n",
    "\n",
    "\\begin{align*}\n",
    "    <f_j,f_k> &= \\int f_j(x) f_k(x) \\text{ } d \\alpha(x) \n",
    "\\end{align*}\n",
    "\n",
    "where $\\alpha$ is a non-decreasing function over the reals. If $<f_j,f_k>$ = 0, then the polynomials are said to be orthogonal. Thus, a spectral method will seek to construct a space of mutually orthogonal functions which we use to approximate the PDE. We will not provide a full discussion of spectral methods in the general sense, but instead will discuss within the context of the Fourier method for the wave equation in one spatial dimension.   \n",
    "\n",
    "### 6  The Fourier Transform \n",
    "\n",
    "Consider the wave equation in one spatial dimension: \n",
    "\n",
    "\\begin{align}\n",
    "    u_{tt} &= c^2 u_{xx}\n",
    "\\end{align} \n",
    "    \n",
    "Suppose that we wish to to solve with separation of variables, and that we use an ansatz which states that our general solution is one of the following: \n",
    "\n",
    "\\begin{align*}\n",
    "    u_1(x,t) = A(t)coskx && u_2(x,t) = B(t)sinkx\n",
    "\\end{align*}\n",
    "\n",
    "Under the assumption that $u_1$ is a solution, then this implies that $A(t)$ must satisfy:\n",
    "\n",
    "\\begin{align*}\n",
    "    u_{tt} &= c^2 u_{xx} \\\\\n",
    "    A_{tt}coskx &= -c^2 (k^2A(t) coskx) \\\\ \n",
    "    &\\Rightarrow A_{tt} = c^2 k^2 A(t) \\\\ \n",
    "\\end{align*}\n",
    "\n",
    "However, this is a familiar ODE, namely that of a harmonic oscillator. By a similar argument, we can show that $B(t)$ must too be a harmonic oscillator. Furthermore, it is quite easy to show that if $u_1$ and $u_2$ are solutions to (1), then so too is $u_1 + u_2$. Therefore, we may actually write our solution to the wave equation using arbitrary linear combinations of $u_1$ and $u_2$ with varying frequencies $k$.  \n",
    "\n",
    "\\begin{align*}\n",
    "    u(x,t) &= A_1(t)cosk_1 x + B_1(t)sink_1 x + A_2(t)cosk_2 x + B_2(t)sink_2 x + ...\n",
    "\\end{align*}\n",
    "\n",
    "Such a solution works in a discrete setting, where the underlying function that we are approximating solutions for is periodic, and we have a sequence of equally spaced values $k_n$. To bring this into a more general setting, we must work with a continuum of frequencies. Thus, rather than using a sum, we must integrate: \n",
    "\n",
    "\\begin{align*}\n",
    "    u(x,t) &= \\int_{-\\infty}^{\\infty} A(k,t)coskx + B(k,t)sinkx \\text{ } dk\n",
    "\\end{align*}\n",
    "\n",
    "Recall that since $A(t)$ and $B(t)$ are harmonic oscillators, and thus rely on $k$, we must now make explicit that both $A$ and $B$ are actually functions of $k$, since $k$ now ranges over a continuum of values. Thanks to Euler, we may write this in the more concise form \n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathcal{F^{-1}}\\{u(k,t)\\} &= \\int_{-\\infty}^{\\infty} u(k,t) e^{ikx} \\text{ } dk\n",
    "\\end{align*}\n",
    "\n",
    "where, resepctively, $A$ and $B$ correspond to the real and imaginary part of $u$. What we have just derived is the $\\textbf{Inverse Fourier}$ $\\textbf{Transform}$, which describes how we may write $u(x,t)$ as a sum over a continuum of its frequencies. The $\\textbf{Fourier Transform}$ is the integral transform which actually sends $u(x,t)$ from its spatial (or temporal) domain into a representation over a domain of its freqeuncies:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathcal{F}\\{u(x,t)\\} &= \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} u(x,t) e^{-ikx} \\text{ } dx\n",
    "\\end{align*}\n",
    "\n",
    "It is common to include the term $1/\\sqrt{2\\pi}$ to normalize the integral, making the Fourier transform **unitary**, and therefore **symmetric**. The Fourier Transform is useful not only for solving PDEs by hand, but for spectral methods as well. \n",
    "\n",
    "### 7  Fourier Spectral Methods\n",
    "\n",
    "Recall that we previously noted that a spectral method for approximating solutions to PDEs will seek solutions in the form of linear combinations of mutually orthogonal polynomials. In fact, it is quite easy to show that sine and cosine functions of arbitrary frequency are indeed orthogonal over correctly chosen bounds. Let $N \\in \\mathbb{R}^{>0}$ and $m,n \\in \\mathbb{R}$. Using the inner product for polynomials, it follows that\n",
    "\n",
    "\\begin{align*}\n",
    "    \\int_{-N}^{N} cos(mx)sin(nx) \\text{ } dx &= 0. \n",
    "\\end{align*}\n",
    "\n",
    "Although this integral does not converge in the limit as $N \\rightarrow \\infty$, we may still use this to construct a sepctral method since numerical techniqes must place a discretization on the function space. Therefore, we cannot use the Fourier transform in the continuous form that we have written above. What this means is that we must use the **Discrete Fourier Transform**, which is a finite sum ranging over a discretization of the spatial variable $x$. \n",
    "\n",
    "#### 7.1  The Discrete Fourier Transform (DFT) \n",
    "\n",
    "Suppose a sequence of points $x_0, x_1,\\dots x_{n-1}$ where any point $x_j \\in \\mathbb{R}$. Equivalently, we may write this as a vector $X \\in \\mathbb{R}^n$. The DFT will map such a vector in a spatial (or temporal) dimension to a vector $Y \\in \\mathbb{C}^{n}$ given by $(y_0, y_1, \\dots y_{n-1})^{T}$ using the following definition:\n",
    "\n",
    "\\begin{align*}\n",
    "    y_k = \\frac{1}{\\sqrt{n}} \\sum_{j=0}^{n-1} x_j e^{-i 2\\pi jk /n}\n",
    "\\end{align*}\n",
    "\n",
    "We can augment this process to produce the vector $Y$ by constructing the **Fourier Matrix**, $\\mathcal{F}$. Each row of the matrix corresponds to a different value of $k$, and thus a mapping $x_j \\mapsto y_k$: \n",
    "\n",
    "\\begin{align*}\n",
    "    Y &= \\frac{1}{\\sqrt{n}} \\mathcal{F} X\n",
    "\\end{align*}\n",
    "\n",
    "Letting $\\omega = e^{-i2\\pi / n}$, then $\\mathcal{F}$ is defined as the unitary matrix\n",
    "\n",
    "\\begin{align*}\n",
    "    \\begin{pmatrix}\n",
    "        \\omega^0 & \\omega^0 & \\omega^0 & \\dots & \\omega^0 \\\\ \n",
    "        \\omega^0 & \\omega^1 & \\omega^2 & \\dots & \\omega^{n-1} \\\\\n",
    "        \\omega^0 & \\omega^2 & \\omega^4 & \\dots & \\omega^{2(n-1)} \\\\\n",
    "        \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "        \\omega^0 & \\omega^{n-1} & \\omega^{2(n-1)} & \\dots & \\omega^{(n-1)^2} \\\\\n",
    "    \\end{pmatrix}\n",
    "\\end{align*}.\n",
    "\n",
    "Applying the inverse Fourier transform is as simple as applying the matrix $\\mathcal{F}^{-1}$ to some vector. Since $\\mathcal{F}$ is unitary, then $\\mathcal{F} = \\overline{\\mathcal{F}}^T$. This property is rather useful to exemplify why it is common to normalize both the continuous and discrete Fourier transforms. This matrix-vector product is the foundation of a class of algorithms dedicated to computing a discrete Fourier transform, most notably Fast Fourier Transfrom (FFT) algorithms. For our purpose, the FFT will be useful in implementing a Fourier spectral method.\n",
    "\n",
    "#### 7.2  Fast Fourier Trasnform \n",
    "\n",
    "There is a rich history of Fast Fourier Transform algorithms. The most commonly used variation is that of Cooley and Tukey, first described in their 1965 paper. This is a recursive, divide and conquer algorithm, and thus works best for input sizes which are powers of two. However, other variations exist, such as the Good's prime factor FFT, which is efficient for input data of relatively prime size, and makes use of the Chinese Remainder Theorem. In fact, Good's work was a first step to inspiring Cooley and Tukey's algorithm. Before either of these implementations, the algorithm was first described, albeit in less detial, by Gauss. Today, most imlementations use the Cooley and Tukey algorithm, or some variation. \n",
    "\n",
    "Since the DFT is a matrix-vector product, a straightforward algorithm to compute would typically be quadratic in the size of the vector which the transform is applied to. However, the Cooley and Tukey algorithm provides an alternative which runs in loglinear time (at worst) by taking advantage of the recursive structure of the DFT. Here, we motivate how and why the FFT works, without explicitly proving it's time complexity.\n",
    "\n",
    "The key insight is in fact a simple consequence of the properties of exponential functions as well as properties of complex conjugates, which is stated with the following proposition.  \n",
    "\n",
    "*Proposition:* Suppose $Y = \\{y_k\\}$ is the Fourier Transform of $X = \\{x_j\\}$ where $X \\in \\mathbb{R}^n$. It follows that $y_0 \\in \\mathbb{R}$ and $y_{n-k} = \\overline{y_k}$ for each $k \\in \\{1, \\dots, n-1\\}$. \n",
    "\n",
    "*Proof:* Part a follows immediately from inspection of the definition of the DFT, and is a simple conseqeunce of the fact that $e^0 = 1$. Therefore, for $k=0$, we have: \n",
    "\n",
    "\\begin{align*}\n",
    "    y_0 = \\frac{1}{\\sqrt{n}} \\sum_{j=0}^{n-1} x_j \n",
    "\\end{align*}\n",
    "\n",
    "Part b is slightly less trivial. First, consider $y_{n-k}$, where once agian we take $\\omega = e^{-i2\\pi / n}$ \n",
    "\n",
    "\\begin{align*}\n",
    "    y_{n-k} &= \\frac{1}{\\sqrt{n}} \\sum_{j=0}^{n-1} x_j (\\omega^{n-k})^j\n",
    "\\end{align*}\n",
    "\n",
    "Using Euler's formula, closer inspection of $\\omega^{n-k}$ implies that \n",
    "\n",
    "\\begin{align*}\n",
    "    \\omega^{n-k} &= e^{-i2\\pi(n-k)/n} \\\\\n",
    "    &= e^{(-i2\\pi n)/n} e^{(i2\\pi k)/n} \\\\\n",
    "    &= e^{-i2\\pi} e^{(i2\\pi k)/n} \\\\\n",
    "    &= e^{(i2\\pi k)/n} \\\\\n",
    "    &= cos(\\frac{2\\pi k}{n}) + i sin(\\frac{2\\pi k}{n})\n",
    "\\end{align*}\n",
    "\n",
    "Furthermore, \n",
    "\n",
    "\\begin{align*}\n",
    "    \\omega^{k} &= e^{-i2\\pi k/n} \\\\\n",
    "    &= cos(\\frac{2\\pi k}{n}) - i sin(\\frac{2\\pi k}{n}).\n",
    "\\end{align*}\n",
    "\n",
    "Therefore $\\omega^{n-k} = \\overline{\\omega^k}$. Returning to $y_{n-k}$, we have \n",
    "\n",
    "\\begin{align*}\n",
    "    y_{n-k} &= \\frac{1}{\\sqrt{n}} \\sum_{j=0}^{n-1} x_j (\\omega^{n-k})^j \\\\ \n",
    "    &= \\frac{1}{\\sqrt{n}} \\sum_{j=0}^{n-1} x_j (\\overline{\\omega^k})^j \\\\\n",
    "    &= \\frac{1}{\\sqrt{n}} \\sum_{j=0}^{n-1} \\overline{x_j (\\omega^k)^j} \\\\\n",
    "    &= \\overline{y_k} \n",
    "\\end{align*}\n",
    "\n",
    "This concludes the proof. Above, we use two key facts to arrive at the final result. First, since $X \\in \\mathbb{R}^n$, then $\\overline{x_j} = x_j$. Second, the product of complex conjugates is equal to the conjugate of their product. The implications of this proposition are rather important. What this means is that ${y_k}$ is in the form\n",
    "\n",
    "\\begin{align*}\n",
    "    (y_0, \\dots, y_{\\frac{n}{2}-1}, y_{\\frac{n}{2}}, \\overline{y_{\\frac{n}{2}-1}}, \\dots, \\overline{y_1})^T, \n",
    "\\end{align*}\n",
    "\n",
    "and therefore, the DFT of a real vector will result in a complex vector where half of the information contained is just the complex conjugate of another entry in the vector. Thus, we can break our probelm down recursively, and each computation of a DFT of size $n$ is equivalent to two DFTs of size $n/2$. The FFT will recursively break the problem into DFTs of smaller size until hitting the base case of size $2$. From there, we reconstruct larger solutions using multiplication and addition operations, and finally a division by $\\sqrt{n}$. We do not explicitly include pseudocode for the FFT in this note.\n",
    "\n",
    "### 8  Implementation\n",
    "\n",
    "To start, let's make the assumption that for the one-dimensional wave equation $u_{tt} = c^2 u_{xx}$, we may write $u(x,t)$ as a product of functions with respect to $x$ and $t$. More specifically, we have\n",
    "\n",
    "\\begin{align*}\n",
    "    u(x,t) &= \\phi(x)\\psi(t).\n",
    "\\end{align*}\n",
    "\n",
    "With this assumption, it follows that:\n",
    "\n",
    "\\begin{align}\n",
    "    \\phi \\psi_{tt} = c^2 \\phi_{xx} \\psi \\Rightarrow \\frac{\\psi_{tt}(t)}{\\psi(t)} = c^2 \\frac{\\phi_{xx}(x)}{\\phi(x)}\n",
    "\\end{align}\n",
    "\n",
    "However, this implies that:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{d}{dt} (\\frac{\\psi_{tt}(t)}{\\psi(t)}) = \\frac{\\partial}{\\partial t} (c^2 \\frac{\\phi_{xx}(x)}{\\phi(x)}) = 0 \n",
    "\\end{align*}\n",
    "\n",
    "Therefore, by a simple application of the constancy theorem, it follows that the RHS and LHS of (2) are constant. Here, we write this as follows: \n",
    "\n",
    "\\begin{align*}\n",
    "    - \\lambda^2 = \\frac{\\psi_{tt}(t)}{\\psi(t)} = c^2 \\frac{\\phi_{xx}(x)}{\\phi(x)}\n",
    "\\end{align*}\n",
    "\n",
    "The assumption that this constant is of the form $- \\lambda^2$ is rather important. With this, it is quite simple to show that the following are general solutions to $\\phi$ and $\\psi$: \n",
    "\n",
    "\\begin{align*}\n",
    "    \\psi(t) = \\alpha_1 e^{\\lambda t} + \\alpha_2 e^{-\\lambda t}, && \\phi(x) = \\gamma_1 e^{\\frac{\\lambda t}{c}} + \\gamma_2 e^{\\frac{-\\lambda t}{c}}\n",
    "\\end{align*}\n",
    "\n",
    "Using these general solutions, and letting $\\lambda = ij$ and $\\frac{\\lambda}{c} = ik$, we now have \n",
    "\n",
    "\\begin{align*}\n",
    "    u(x,t) &= (\\sum \\alpha_j e^{ijx})(\\sum \\gamma_k e^{ikt}),\n",
    "\\end{align*}\n",
    "\n",
    "where $\\{\\alpha_j\\}$ and $\\{\\gamma_k\\}$ are complex vectors computed with the DFT. As an aside, note that with this assumption, we now have \n",
    "\n",
    "\\begin{align*}\n",
    "    \\lambda = ij \\text{ and } \\frac{\\lambda}{c} = ik \\Rightarrow c = \\frac{j}{k}, \n",
    "\\end{align*}\n",
    "\n",
    "where $j$ is associated with some $\\Delta x$ and $k$ is associated with some $\\Delta t$. As $c$ corresponds to the speed coefficient of the wave equation, this assumption makes sense. As a simplifying assumption, we can alternatively assume that both $\\{\\alpha_j\\}, \\{\\gamma_k\\} \\in \\mathbb{C}^n$, thus allowing us to write $u(x,t)$ in the more concise form\n",
    "\n",
    "\\begin{align*}\n",
    "     u(x,t) &= \\sum_{j=0}^{n-1} \\alpha_j e^{ijx} \\gamma_j e^{ijt}.\n",
    "\\end{align*}\n",
    "\n",
    "At an implementation level, finding solutions to the wave equation now decomposes into solving the following set of IVPs: \n",
    "\n",
    "\\begin{align*}\n",
    "    u(x,0) = \\sum \\sigma_j e^{ijx}, u_t(x,0) = 0 \\\\ \n",
    "    u(x,0) = 0, u_t(x,0) = \\sum \\tau_j e^{ijx}, \\\\ \n",
    "\\end{align*}\n",
    "\n",
    "where the first set corresponds to a standing wave at $t=0$, and the second corresponds to the velocity of that wave at $t=0$. This project includes an incomplete implementation of the Fourier spectral method, which uses SciPy's FFT package and a hardcoded version of the inverse DFT to interoplate randomly generated data which is evenly spaced and periodic. \n",
    "\n",
    "### 9  Conclusion\n",
    "\n",
    "We have described in detail how to construct both a finite differences and Fourier spectral approach to approixmate solutions to PDEs. Specifically, we use the wave equation to motivate discussion and implementation of these techniques. Throughout, we have appealed to well known results of Analysis and Fourier Analysis and used tools of linear algebra to provide a solid mathematical foundation to this work. Finally, we have briefly noted implementation level techniques to increase efficincy for finite differences as well as the advantge of spectral methods in providing smooth, polynomial approximations to PDEs. Natural extensions of this work would be a complete implementation of the Fourier Spectral method, as well as discussion and implementations of other techniques, such as FEMs and Finite Volumes. \n",
    "\n",
    "###  References \n",
    "\n",
    "[1] Lentz, C. (2023). âChristian Lentz: Math 437 Capstone.â GitHub, [github.com/ChristianLentz/Math437Capstone/tree/main](github.com/ChristianLentz/Math437Capstone/tree/main). \n",
    "\n",
    "[2] Cooley, J. W., & Tukey, J. W. (1965). *An algorithm for the machine calculation of complex Fourier series*. Mathematics of computation, 19(90), 297-301.\n",
    "\n",
    "[3] Courant, R., Friedrichs, K. and Lewy, H., *On the Partial Difference Equations of Mathematical Physics*. IBM Journal of Research and Development, vol. 11, no. 2, pp. 215-234, March 1967, doi: 10.1147/rd.112.0215.\n",
    "\n",
    "[4] Good I. J. (1958). *The interaction algorithm and practical Fourier analysis*, Journal of the Royal Statistical Society: Series B (Methodological), Volume 20, Issue 2, Pages 361â372.\n",
    "\n",
    "[5] Sauer, T. (2011). *Numerical analysis*. Chapter 10: Trigonometric Interpolation and the FFT. Addison-Wesley Publishing Company.\n",
    "\n",
    "[6] âScipy.Fft.Fft#.â Scipy.Fft.Fft - SciPy v1.11.4 Manual, [docs.scipy.org/doc/scipy/reference/generated/scipy.fft.fft.html](docs.scipy.org/doc/scipy/reference/generated/scipy.fft.fft.html).  \n",
    "\n",
    "[7] SÃ¼li, E. *A Brief Introduction to the Numerical Analysis of PDEs*. \n",
    "\n",
    "[8] Lui S. H. (2012). *Numerical analysis of partial differential equations*. John Wiley & Sons.\n",
    "\n",
    "[9] WÃ¶rner, S. (2008). *Fast Fourier transform*. Swis Federal Institute of Technology Zurich, 10."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
